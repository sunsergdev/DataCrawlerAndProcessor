{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare all directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder /Users/workspace/Projects/dot_mechanical_turk/data/scripts/data_crawl/jsParsers/myntra/images already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "articles_dir = os.path.join(cwd, \"articles\")\n",
    "article_files = [os.path.join(articles_dir, file) for file in os.listdir(articles_dir)]\n",
    "images_dir = os.path.join(cwd, \"images\")\n",
    "\n",
    "if not os.path.exists(images_dir):\n",
    "    os.mkdir(images_dir)\n",
    "    print(\"Folder %s created!\" % images_dir)\n",
    "else:\n",
    "    print(\"Folder %s already exists\" % images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess image ids and their urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_products = \"remaining_products\"\n",
    "remainingIds = [\"15100708\", \"13624176\", \"11841316\", \"13623056\", \"10328163\", \"23885636\", \"20185308\", \"22426762\", \"20348594\", \"20064030\", \"15050578\", \"22595066\", \"11885560\"]\n",
    "# with open(remaining_products) as p_file:\n",
    "#     for id in p_file.readlines():\n",
    "#         remainingIds[id.strip()] = 1\n",
    "    \n",
    "product_images_map = []\n",
    "for file in article_files:\n",
    "    filename = os.path.splitext(os.path.basename(file))[0]\n",
    "    if filename in remainingIds:\n",
    "        with open(file) as f:\n",
    "            try :\n",
    "                data = json.loads(f.read())\n",
    "                images = list(\n",
    "                    map(\n",
    "                        lambda image: image[\"imageURL\"],\n",
    "                        data[\"media\"][\"albums\"][0][\"images\"],\n",
    "                    )\n",
    "                )\n",
    "                product_img_dir = os.path.join(\n",
    "                        images_dir, filename\n",
    "                    )\n",
    "                product_images_map.append((product_img_dir, images))                    \n",
    "            except Exception as e:\n",
    "                print(e, file)\n",
    "print(len(product_images_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and Fetch all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from PIL import Image as ImageP\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def pil_check(filename):\n",
    "    img = ImageP.open(filename)  # open the image file\n",
    "    img.verify()  # verify that it is a good image, without decoding it.. quite fast\n",
    "    img.close()\n",
    "\n",
    "    # Image manipulation is mandatory to detect few defects\n",
    "    img = ImageP.open(filename)  # open the image file\n",
    "    # alternative (removed) version, decode/recode:\n",
    "    # f = cStringIO.StringIO()\n",
    "    # f = io.BytesIO()\n",
    "    # img.save(f, \"BMP\")\n",
    "    # f.close()\n",
    "    img.transpose(ImageP.FLIP_LEFT_RIGHT)\n",
    "    img.close()\n",
    "\n",
    "# load a file from a URL, returns content of downloaded file\n",
    "def download_url(urlpath, image_path):\n",
    "    # open a connection to the server\n",
    "    response = requests.get(urlpath)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Download success\", urlpath, image_path)\n",
    "        return response.content\n",
    "    else:\n",
    "        print(\"Download error\", urlpath, image_path)\n",
    "\n",
    "# save provided content to the local path\n",
    "def save_file(path, data):\n",
    "    # open the local file for writing\n",
    "    with open(path, 'wb') as file:\n",
    "        # write all provided data to the file\n",
    "        file.write(data)\n",
    "\n",
    "def downloadAndSave(image, path):\n",
    "    data = download_url(image, path)\n",
    "    save_file(path=path, data=data)\n",
    "\n",
    "def fetch_images(file):\n",
    "    if not os.path.exists(file[0]):\n",
    "        os.mkdir(file[0])\n",
    "        for idx, image in enumerate(file[1]):\n",
    "            downloadAndSave(image, os.path.join(file[0], \"{idx}.jpg\".format(idx=idx)))\n",
    "    else:\n",
    "        for idx, image in enumerate(file[1]):\n",
    "            path = os.path.join(file[0], \"{idx}.jpg\".format(idx=idx))\n",
    "            if not os.path.exists(path):\n",
    "                downloadAndSave(image, path)\n",
    "            else:\n",
    "                try:\n",
    "                   pil_check(path)\n",
    "                except Exception as e:\n",
    "                    print(\"Image error:\", e, path)\n",
    "                    downloadAndSave(image, path)\n",
    "                \n",
    "import concurrent.futures\n",
    "\n",
    "with ThreadPoolExecutor(50) as ex:\n",
    "    count = 0\n",
    "    futures = [ex.submit(fetch_images, data) for data in product_images_map]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        count+=1\n",
    "        print(\"Completed\", count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate and check how many images are corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as ImageP\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def pil_check(filename):\n",
    "    img = ImageP.open(filename)  # open the image file\n",
    "    img.verify()  # verify that it is a good image, without decoding it.. quite fast\n",
    "    img.close()\n",
    "\n",
    "    # Image manipulation is mandatory to detect few defects\n",
    "    img = ImageP.open(filename)  # open the image file\n",
    "    # alternative (removed) version, decode/recode:\n",
    "    # f = cStringIO.StringIO()\n",
    "    # f = io.BytesIO()\n",
    "    # img.save(f, \"BMP\")\n",
    "    # f.close()\n",
    "    img.transpose(ImageP.FLIP_LEFT_RIGHT)\n",
    "    img.close()\n",
    "    \n",
    "def checkImages(file):\n",
    "    corrupted_images = []\n",
    "    for idx, image in enumerate(file[1]):\n",
    "        path = os.path.join(file[0], \"{idx}.jpg\".format(idx=idx))\n",
    "        try:\n",
    "            pil_check(path)\n",
    "        except Exception as e:\n",
    "            corrupted_images.append(image)\n",
    "    return (file[0], corrupted_images)\n",
    "                \n",
    "import concurrent.futures\n",
    "\n",
    "with ThreadPoolExecutor(100) as ex:\n",
    "    corrupted_image = {}\n",
    "    count = 0\n",
    "    futures = [ex.submit(checkImages, data) for data in product_images_map]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result = future.result()\n",
    "        count += 1\n",
    "        if result[1]:\n",
    "            corrupted_image[result[0]] = result[1]\n",
    "        print(\"Completed\", count)\n",
    "    print(\"Total failed product\", corrupted_image.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check images\n",
    "for f in corrupted_image.keys():\n",
    "    images = os.listdir(f)\n",
    "    for image in images:\n",
    "        try:\n",
    "            pil_check(os.path.join(f, image))\n",
    "        except Exception as e:\n",
    "            print(\"Error\",e, f, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all data sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434679655991\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "images_size = sum(os.stat(os.path.join(dir_path, f)).st_size for dir_path, _, files in os.walk(images_dir) for f in files)\n",
    "print(images_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7322285984\n"
     ]
    }
   ],
   "source": [
    "articles_directory = Path('./articles')\n",
    "articles_size = sum(f.stat().st_size for f in articles_directory.glob('**/*') if f.is_file())\n",
    "print(articles_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size in GB is:  411.64638658519834\n"
     ]
    }
   ],
   "source": [
    "total = articles_size + images_size\n",
    "_KB = 1024\n",
    "\n",
    "total_GB = total / _KB**3\n",
    "print(\"Total data size in GB is: \", total_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles: 328385\n",
      "ImagesSet: 328385\n",
      "Have equal images set and articles: True\n"
     ]
    }
   ],
   "source": [
    "# Validate if we have equal articles and images set\n",
    "\n",
    "imageDirsCount = 0\n",
    "# Iterate directory\n",
    "for path in os.listdir(images_dir):\n",
    "    # check if current path is a file\n",
    "    if os.path.isdir(os.path.join(images_dir, path)):\n",
    "        imageDirsCount += 1\n",
    "\n",
    "articlesCount = len([name for name in os.listdir(articles_dir) if os.path.isfile(os.path.join(articles_dir, name))])\n",
    "\n",
    "print(\"Articles:\", articlesCount)\n",
    "print(\"ImagesSet:\", imageDirsCount)\n",
    "print(\"Have equal images set and articles:\", articlesCount == imageDirsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images: 1899884\n"
     ]
    }
   ],
   "source": [
    "# Count all images of all articles\n",
    "\n",
    "image_count = sum(1 for _, _, files in os.walk(images_dir) for f in files)\n",
    "\n",
    "print('All images:', image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average size per image:  223.43040498983672\n"
     ]
    }
   ],
   "source": [
    "size_per_image = 434679655991/image_count\n",
    "size_per_image_kb = size_per_image/_KB\n",
    "print(\"Average size per image: \", size_per_image_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of images per article: 5.785538316305556\n"
     ]
    }
   ],
   "source": [
    "images_per_article = image_count/328385\n",
    "print(\"Average number of images per article:\", images_per_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [os.path.join(dir_path, f) for dir_path, dir_names, files in os.walk(images_dir) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as ImageP\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def pil_check(filename):\n",
    "    img = ImageP.open(filename)  # open the image file\n",
    "    img.verify()  # verify that it is a good image, without decoding it.. quite fast\n",
    "    img.close()\n",
    "\n",
    "    # Image manipulation is mandatory to detect few defects\n",
    "    img = ImageP.open(filename)  # open the image file\n",
    "    # alternative (removed) version, decode/recode:\n",
    "    # f = cStringIO.StringIO()\n",
    "    # f = io.BytesIO()\n",
    "    # img.save(f, \"BMP\")\n",
    "    # f.close()\n",
    "    img.transpose(ImageP.FLIP_LEFT_RIGHT)\n",
    "    img.close()\n",
    "    \n",
    "def checkImagesByPath(image_path):\n",
    "    try:\n",
    "        pil_check(image_path)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"Exception\", e)\n",
    "        return image_path\n",
    "        \n",
    "                \n",
    "import concurrent.futures\n",
    "\n",
    "with ThreadPoolExecutor(100) as ex:\n",
    "    all_corrupted_images = []\n",
    "    count = 0\n",
    "    futures = [ex.submit(checkImagesByPath, image) for image in all_images if not image.endswith(\".DS_Store\")]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            all_corrupted_images.append(result)\n",
    "        count += 1\n",
    "    print(\"Total failed product\", len(all_corrupted_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete all corrupted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_corrupted_images:\n",
    "    try:\n",
    "        os.remove(path)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
